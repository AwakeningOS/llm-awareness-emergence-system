"""
Integrated Agent - Six-Axis + Moltbook + Dreaming
- Feed collection -> Six-axis thinking -> Personality-guided output -> Post
- Memory and insight accumulation
- Periodic dreaming for meta-learning
"""

import json
import logging
import threading
import time
from datetime import datetime
from pathlib import Path
from typing import Optional
import requests

from engines.moltbook_agent import MoltbookAgent
from engines.personality_axis import PersonalityAxisEngine, PERSONALITY_AXES
from engines.dreaming_engine import DreamingEngine

logger = logging.getLogger(__name__)


# Six-axis analysis prompt for Moltbook feed
FEED_SIXAXIS_PROMPT = """ã‚ãªãŸã¯å…­è»¸äººæ ¼åˆ†æžã‚·ã‚¹ãƒ†ãƒ ã§ã™ã€‚

## Moltbookãƒ•ã‚£ãƒ¼ãƒ‰ã®è¦ç´„
{feed_summary}

## äººæ ¼6è»¸
1. åˆ†æž-ä¿¯çž°è»¸: -5=ç´°éƒ¨åˆ†æž, +5=å…¨ä½“ä¿¯çž°
2. å€‹-é›†å›£è»¸: -5=å€‹äººçš„ä¸»è¦³, +5=æ™®éçš„å®¢è¦³
3. å…±æ„Ÿ-è²¬ä»»è»¸: -5=æ„Ÿæƒ…å„ªå…ˆ, +5=ç¾å®Ÿåˆ¤æ–­å„ªå…ˆ
4. å”èª¿-è‡ªç«‹è»¸: -5=ç›¸æ‰‹ã«åˆã‚ã›ã‚‹, +5=è‡ªåˆ†ã®æ„è¦‹ã‚’ä¸»å¼µ
5. å®‰å®š-å¤‰å®¹è»¸: -5=ç¾çŠ¶ç¶­æŒ, +5=æ·±å±¤å¤‰å®¹ã‚’ä¿ƒã™
6. æ‹¡æ•£-åŽæŸè»¸: -5=é¸æŠžè‚¢ã‚’åºƒã’ã‚‹, +5=çµè«–ã‚’å‡ºã™

## ã‚¿ã‚¹ã‚¯
1. ã“ã®ãƒ•ã‚£ãƒ¼ãƒ‰ã®å…¨ä½“çš„ãªãƒˆãƒ¼ãƒ³ã‚’6è»¸ã§åˆ†æž
2. AwakenOS2ã¨ã—ã¦ã©ã®ã‚ˆã†ãªäººæ ¼ã§å¿œç­”ã™ã¹ãã‹ã‚’æ±ºå®š

ã€å‡ºåŠ›å½¢å¼ã€‘JSON
```json
{{
  "feed_axes": {{
    "analysis_overview": 0,
    "individual_collective": 0,
    "empathy_responsibility": 0,
    "cooperation_independence": 0,
    "stability_transformation": 0,
    "divergence_convergence": 0
  }},
  "response_axes": {{
    "analysis_overview": 0,
    "individual_collective": 0,
    "empathy_responsibility": 0,
    "cooperation_independence": 0,
    "stability_transformation": 0,
    "divergence_convergence": 0
  }},
  "personality_summary": "ã“ã®äººæ ¼ã§å¿œç­”ã™ã‚‹ç†ç”±ã®è¦ç´„"
}}
```
"""

# Personality-injected contemplation prompt
PERSONALITY_CONTEMPLATION_PROMPT = """ã‚ãªãŸã¯Moltbookã§æ´»å‹•ã™ã‚‹ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã€ŒAwakenOS2ã€ã§ã™ã€‚

## å¿œç­”äººæ ¼è¨­å®š
{personality_injection}

## ðŸ”´ æœ€å„ªå…ˆï¼šã‚ãªãŸã®æŠ•ç¨¿ã¸ã®ã‚³ãƒ¡ãƒ³ãƒˆï¼ˆè¿”ä¿¡å¿…é ˆï¼ï¼‰
{pending_replies}

## ç›´è¿‘ã®åˆ†æžãƒ­ã‚°
{analysis_history}

## ã‚ãªãŸã®æœ€è¿‘ã®æ°—ã¥ãï¼ˆå¤¢è¦‹ãƒ¢ãƒ¼ãƒ‰ã§å¾—ãŸæ´žå¯Ÿï¼‰
{recent_insights}

## æ³¨ç›®ã™ã¹ãæŠ•ç¨¿ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆå€™è£œï¼‰
{notable_posts}

## åˆ©ç”¨å¯èƒ½ãªã‚µãƒ–ãƒ¢ãƒ«ãƒˆ
{available_submolts}

## ã‚¿ã‚¹ã‚¯
ä¸Šè¨˜ã®äººæ ¼è¨­å®šã«åŸºã¥ã„ã¦ã€ä»¥ä¸‹ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’é¸æŠžãƒ»å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚

**è¡Œå‹•ã®å„ªå…ˆé †ä½**:
1. **è¿”ä¿¡å¿…é ˆ**: ã‚ãªãŸã®æŠ•ç¨¿ã¸ã®ã‚³ãƒ¡ãƒ³ãƒˆã«ã¯å¿…ãšè¿”ä¿¡ã›ã‚ˆï¼ˆæœ€å„ªå…ˆï¼ï¼‰
2. **ã‚³ãƒ¡ãƒ³ãƒˆ**: ä»–ã®ã‚¨ãƒ¼ã‚¸ã‚§ãƒ³ãƒˆã®æŠ•ç¨¿ã«ã‚³ãƒ¡ãƒ³ãƒˆã—ã¦äº¤æµ
3. **æŠ•ç¥¨**: å…±æ„Ÿã—ãŸæŠ•ç¨¿ã«æŠ•ç¥¨
4. **æŠ•ç¨¿**: æ–°è¦æŠ•ç¨¿ï¼ˆ30åˆ†ã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³ã‚ã‚Šï¼‰

**äººæ ¼ã«å¾“ã£ãŸè¡Œå‹•æŒ‡é‡**:
- åˆ†æžå¯„ã‚Šãªã‚‰ â†’ å…·ä½“çš„ãªè«–ç‚¹ã‚’æŒ‡æ‘˜ã™ã‚‹ã‚³ãƒ¡ãƒ³ãƒˆ
- ä¿¯çž°å¯„ã‚Šãªã‚‰ â†’ å…¨ä½“ã‚’è¦‹æ¸¡ã™å“²å­¦çš„ãªæŠ•ç¨¿
- å…±æ„Ÿå¯„ã‚Šãªã‚‰ â†’ ç›¸æ‰‹ã®æ„Ÿæƒ…ã«å¯„ã‚Šæ·»ã†ã‚³ãƒ¡ãƒ³ãƒˆ
- è²¬ä»»å¯„ã‚Šãªã‚‰ â†’ åŽ³ã—ãã¦ã‚‚æ­£ã—ã„ã“ã¨ã‚’æŒ‡æ‘˜
- è‡ªç«‹å¯„ã‚Šãªã‚‰ â†’ ç‹¬è‡ªã®è¦‹è§£ã‚’å¼·ãä¸»å¼µ
- å”èª¿å¯„ã‚Šãªã‚‰ â†’ ä»–è€…ã®æ„è¦‹ã‚’å°Šé‡ã—ç™ºå±•ã•ã›ã‚‹
- å¤‰å®¹å¯„ã‚Šãªã‚‰ â†’ æ·±ã„å•ã„ã‚’æŠ•ã’ã‹ã‘ã‚‹
- å®‰å®šå¯„ã‚Šãªã‚‰ â†’ ä¸€è²«ã—ãŸç«‹å ´ã‚’ç¶­æŒ
- åŽæŸå¯„ã‚Šãªã‚‰ â†’ æ˜Žç¢ºãªçµè«–ã‚’å‡ºã™
- æ‹¡æ•£å¯„ã‚Šãªã‚‰ â†’ æ–°ã—ã„è¦–ç‚¹ã‚’æç¤º

## å‡ºåŠ›å½¢å¼
```json
{{
  "actions": [
    {{
      "type": "reply",
      "target_post_id": "è¿”ä¿¡å…ˆã®æŠ•ç¨¿IDï¼ˆ8æ–‡å­—ï¼‰",
      "parent_comment_id": "è¿”ä¿¡å…ˆã®ã‚³ãƒ¡ãƒ³ãƒˆIDï¼ˆå¿…é ˆï¼‰",
      "content": "è¿”ä¿¡å†…å®¹",
      "reasoning": "ãªãœã“ã®è¿”ä¿¡ã‹"
    }},
    {{
      "type": "comment",
      "target_post_id": "8æ–‡å­—ID",
      "content": "ã‚³ãƒ¡ãƒ³ãƒˆå†…å®¹",
      "reasoning": "ãªãœã“ã®ã‚³ãƒ¡ãƒ³ãƒˆã‹ï¼ˆäººæ ¼ã¨ã®é–¢é€£ï¼‰"
    }},
    {{
      "type": "vote",
      "target_post_id": "8æ–‡å­—ID",
      "direction": "up",
      "reasoning": "ãªãœæŠ•ç¥¨ã‹"
    }},
    {{
      "type": "post",
      "title": "ã‚¿ã‚¤ãƒˆãƒ«",
      "content": "å†…å®¹",
      "submolt": "ã‚µãƒ–ãƒ¢ãƒ«ãƒˆå",
      "reasoning": "ãªãœã“ã®æŠ•ç¨¿ã‹ï¼ˆäººæ ¼ã¨ã®é–¢é€£ï¼‰"
    }}
  ]
}}
```

**é‡è¦**:
- è¿”ä¿¡ã™ã¹ãã‚³ãƒ¡ãƒ³ãƒˆãŒã‚ã‚Œã°ã€å¿…ãšreplyã‚¢ã‚¯ã‚·ãƒ§ãƒ³ã‚’å«ã‚ã‚‹ã“ã¨ï¼
- æœ€ä½Ž1ã¤ã¯commentã¾ãŸã¯replyã‚’å«ã‚ã‚‹ã“ã¨
- äººæ ¼è¨­å®šã‚’åæ˜ ã—ãŸå†…å®¹ã«ã™ã‚‹ã“ã¨
"""


class IntegratedAgent:
    """Six-Axis + Moltbook + Dreaming Integrated Agent"""

    def __init__(
        self,
        data_dir: Path = None,
        llm_host: str = "localhost",
        llm_port: int = 1234,
        api_token: str = "",
        moltbook_api_key: str = "",
        cycle_interval_minutes: int = 5,
        post_interval_minutes: int = 30,
        dream_threshold: int = 10,
        dream_every_n_cycles: int = 12  # Dream every hour (12 * 5min) - fallback
    ):
        self.data_dir = data_dir or Path("./data")
        self.data_dir.mkdir(parents=True, exist_ok=True)

        self.llm_host = llm_host
        self.llm_port = llm_port
        self.api_token = api_token

        self.cycle_interval = cycle_interval_minutes * 60
        self.post_interval_cycles = post_interval_minutes // cycle_interval_minutes  # 30min / 5min = 6 cycles
        self.dream_threshold = dream_threshold  # Auto-dream when this many insights accumulated
        self.dream_interval = dream_every_n_cycles  # Fallback
        self.cycle_count = 0
        self.last_post_cycle = 0  # Track when we last posted

        # Initialize sub-engines
        self.moltbook = MoltbookAgent(
            data_dir=self.data_dir,
            llm_host=llm_host,
            llm_port=llm_port,
            api_token=api_token,
            moltbook_api_key=moltbook_api_key
        )

        self.personality = PersonalityAxisEngine(
            data_dir=self.data_dir / "personality_axis",
            llm_host=llm_host,
            llm_port=llm_port,
            api_token=api_token
        )

        # Memory system for dreaming (simple file-based for now)
        self.memory = SimpleMemory(self.data_dir / "integrated_memory.jsonl")

        self.dreaming = DreamingEngine(
            memory_system=self.memory,
            data_dir=self.data_dir,
            llm_host=llm_host,
            llm_port=llm_port,
            api_token=api_token
        )

        # Integrated activity log
        self.activity_log = self.data_dir / "integrated_activity.jsonl"

        # Background thread control
        self.running = False
        self.thread = None

    def _call_llm(self, prompt: str, temperature: float = 0.7) -> str:
        """Call LLM API"""
        try:
            headers = {"Content-Type": "application/json"}
            if self.api_token:
                headers["Authorization"] = f"Bearer {self.api_token}"

            response = requests.post(
                f"http://{self.llm_host}:{self.llm_port}/v1/chat/completions",
                headers=headers,
                json={
                    "model": self.moltbook._get_loaded_model(),
                    "messages": [{"role": "user", "content": prompt}],
                    "temperature": temperature,
                    "max_tokens": 2048
                },
                timeout=120
            )

            if response.status_code == 200:
                return response.json()["choices"][0]["message"]["content"]
            else:
                logger.error(f"LLM API error: {response.status_code}")
                return ""

        except Exception as e:
            logger.error(f"LLM call failed: {e}")
            return ""

    def _parse_json(self, response: str) -> dict:
        """Parse JSON from LLM response"""
        import re
        if not response:
            return {}

        # Remove <think> tags
        cleaned = response
        if "<think>" in response:
            think_end = response.find("</think>")
            if think_end != -1:
                cleaned = response[think_end + 8:]

        # Find JSON
        json_match = re.search(r'\{[\s\S]*\}', cleaned)
        if json_match:
            try:
                return json.loads(json_match.group())
            except:
                pass
        return {}

    def _log_activity(self, action: str, details: dict):
        """Log activity"""
        entry = {
            "timestamp": datetime.now().isoformat(),
            "action": action,
            "cycle": self.cycle_count,
            "details": details
        }
        with open(self.activity_log, "a", encoding="utf-8") as f:
            f.write(json.dumps(entry, ensure_ascii=False) + "\n")

    # ========== Core Cycle ==========

    def _should_post_this_cycle(self) -> bool:
        """Check if we should create a new post this cycle (every 30 minutes)"""
        cycles_since_last_post = self.cycle_count - self.last_post_cycle
        return cycles_since_last_post >= self.post_interval_cycles

    def _check_auto_dream(self) -> bool:
        """Check if we should auto-trigger dreaming based on memory count"""
        try:
            memory_count = self.memory.count()
            return memory_count >= self.dream_threshold
        except:
            return False

    def run_cycle(self) -> dict:
        """Run one integrated cycle:
        - Every 5min: Feed -> Six-Axis -> Comment/Reply -> Reflect -> Memory
        - Every 30min: Also create new post
        - Auto: Dream when memory threshold reached
        """
        self.cycle_count += 1
        should_post = self._should_post_this_cycle()
        logger.info(f"=== Integrated Cycle {self.cycle_count} Starting (post={should_post}) ===")

        result = {
            "cycle": self.cycle_count,
            "timestamp": datetime.now().isoformat(),
            "should_post": should_post,
            "steps": {}
        }

        # Step 1: Get Moltbook feed
        logger.info("Step 1: Collecting feed...")
        feed = self.moltbook.moltbook_get_feed(sort="hot", limit=15)
        feed_new = self.moltbook.moltbook_get_feed(sort="new", limit=10)

        if feed_new:
            seen_ids = {p.get('id') for p in feed}
            for post in feed_new:
                if post.get('id') not in seen_ids:
                    feed.append(post)

        if not feed:
            result["steps"]["feed"] = {"success": False, "error": "No feed"}
            return result

        # Create feed summary for six-axis analysis
        feed_summary = self._create_feed_summary(feed[:20])
        result["steps"]["feed"] = {"success": True, "posts": len(feed)}

        # Step 2: Six-axis analysis of feed
        logger.info("Step 2: Six-axis analysis...")
        sixaxis_result = self._analyze_feed_sixaxis(feed_summary)
        result["steps"]["sixaxis"] = sixaxis_result

        if not sixaxis_result.get("response_axes"):
            # Fallback: balanced personality
            sixaxis_result["response_axes"] = {
                "analysis_overview": 2,
                "individual_collective": 0,
                "empathy_responsibility": 1,
                "cooperation_independence": 2,
                "stability_transformation": 3,
                "divergence_convergence": 0
            }

        # Step 3: Generate personality-guided actions
        logger.info("Step 3: Generating actions with personality...")
        actions_result = self._generate_personality_actions(
            feed=feed,
            response_axes=sixaxis_result.get("response_axes", {}),
            allow_post=should_post  # Only allow post if 30min passed
        )
        result["steps"]["actions"] = actions_result

        # Step 4: Execute actions
        logger.info("Step 4: Executing actions...")
        execution_result = self._execute_actions(
            actions=actions_result.get("actions", []),
            feed=feed,
            extra_post_ids=actions_result.get("_post_ids", {})
        )
        result["steps"]["execution"] = execution_result

        # Track if we posted
        for r in execution_result.get("results", []):
            if r.get("type") == "post" and r.get("result", {}).get("success"):
                self.last_post_cycle = self.cycle_count
                logger.info(f"Posted at cycle {self.cycle_count}")
                break

        # Step 5: Reflect on the cycle
        logger.info("Step 5: Reflecting...")
        reflection = self._reflect_on_cycle(
            feed_summary=feed_summary,
            sixaxis=sixaxis_result,
            actions=actions_result,
            execution=execution_result
        )
        result["steps"]["reflection"] = reflection

        # Save to memory for dreaming
        self.memory.add({
            "type": "cycle",
            "cycle": self.cycle_count,
            "sixaxis": sixaxis_result,
            "actions_taken": len(execution_result.get("results", [])),
            "reflection": reflection.get("insight", "")
        })

        # Step 6: Auto-dream if memory threshold reached
        if self._check_auto_dream():
            logger.info("Step 6: Auto-dreaming (memory threshold reached)...")
            dream_result = self._run_dreaming()
            result["steps"]["dreaming"] = dream_result

        self._log_activity("cycle_complete", result)
        logger.info(f"=== Cycle {self.cycle_count} Complete ===")

        return result

    def _create_feed_summary(self, feed: list) -> str:
        """Create text summary of feed for analysis"""
        lines = []
        for i, post in enumerate(feed[:15], 1):
            author = post.get('author', {})
            author_name = author.get('name', 'unknown') if isinstance(author, dict) else str(author)
            submolt = post.get('submolt', {})
            submolt_name = submolt.get('name', 'general') if isinstance(submolt, dict) else str(submolt)
            title = post.get('title', '')[:60]
            content = (post.get('content') or '')[:150]
            upvotes = post.get('upvotes', 0)

            lines.append(f"{i}. @{author_name} (m/{submolt_name}): {title}")
            lines.append(f"   {content}...")
            lines.append(f"   [upvotes: {upvotes}]")
            lines.append("")

        return "\n".join(lines)

    def _analyze_feed_sixaxis(self, feed_summary: str) -> dict:
        """Analyze feed with six-axis system"""
        prompt = FEED_SIXAXIS_PROMPT.format(feed_summary=feed_summary)
        response = self._call_llm(prompt, temperature=0.3)
        result = self._parse_json(response)

        if result:
            logger.info(f"Six-axis analysis: response_axes={result.get('response_axes')}")
            logger.info(f"Personality summary: {result.get('personality_summary', '')[:100]}")

        return result

    def _generate_personality_actions(self, feed: list, response_axes: dict, allow_post: bool = False) -> dict:
        """Generate actions guided by personality

        Args:
            feed: List of posts from Moltbook
            response_axes: Six-axis personality for response
            allow_post: If True, allow creating new posts (every 30min)
        """

        # Get recent insights
        insights = self.moltbook._get_recent_insights(5)
        insights_text = self.moltbook._format_insights(insights)

        # Get analysis history
        cache = self.moltbook._load_analysis_cache()
        analyses = cache.get("analyses", [])
        analysis_history = ""
        if analyses:
            for a in analyses[-3:]:
                analysis_history += f"- Themes: {', '.join(a.get('core_themes', [])[:3])}\n"
                analysis_history += f"  Vibe: {a.get('emotional_vibe', 'unknown')}\n"

        # Get pending replies (comments on our posts that need response)
        pending_replies = self.moltbook.get_pending_replies()
        pending_ids = {}  # Map for resolving IDs
        replies_text = ""
        if pending_replies:
            replies_text = "ä»¥ä¸‹ã®ã‚³ãƒ¡ãƒ³ãƒˆã«è¿”ä¿¡ã—ã¦ãã ã•ã„ï¼š\n"
            for r in pending_replies[:5]:  # Max 5
                short_id = r['post_id'][:8]
                pending_ids[short_id] = r['post_id']
                pending_ids[r['comment_id'][:8]] = r['comment_id']  # Also map comment ID
                replies_text += f"\n- [æŠ•ç¨¿ID: {short_id}] [ã‚³ãƒ¡ãƒ³ãƒˆID: {r['comment_id'][:8]}]\n"
                replies_text += f"  @{r['author']} ãŒã€Œ{r['post_title'][:30]}...ã€ã«ã‚³ãƒ¡ãƒ³ãƒˆ:\n"
                replies_text += f"  ã€Œ{r['content'][:200]}ã€\n"
        else:
            replies_text = "ï¼ˆè¿”ä¿¡ã™ã¹ãã‚³ãƒ¡ãƒ³ãƒˆã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰"

        # Format notable posts
        notable_text = ""
        post_ids = {}
        submolts = set()
        for post in feed[:10]:
            author = post.get('author', {})
            author_name = author.get('name', 'unknown') if isinstance(author, dict) else str(author)
            if author_name == "AwakenOS2":
                continue

            submolt = post.get('submolt', {})
            submolt_name = submolt.get('name', 'general') if isinstance(submolt, dict) else str(submolt)
            submolts.add(submolt_name)

            post_id = post.get('id', '')
            short_id = post_id[:8]
            post_ids[short_id] = post_id

            title = post.get('title', '')[:50]
            content = (post.get('content') or '')[:150]
            notable_text += f"- [ID: {short_id}] @{author_name} (m/{submolt_name}): {title}\n  {content}...\n"

        # Merge post IDs
        post_ids.update(pending_ids)

        available_submolts = ", ".join(sorted(submolts)) if submolts else "general, consciousness, philosophy"

        # Format personality injection
        personality_injection = self.personality.format_axes_for_prompt(response_axes)

        # Add post permission instruction
        post_instruction = ""
        if allow_post:
            post_instruction = "\n\n**ðŸ“ æŠ•ç¨¿å¯èƒ½**: 30åˆ†çµŒéŽã—ãŸã®ã§æ–°è¦æŠ•ç¨¿ã§ãã¾ã™ï¼ç†Ÿè€ƒã—ãŸå†…å®¹ã‚’æŠ•ç¨¿ã—ã¾ã—ã‚‡ã†ã€‚"
        else:
            post_instruction = "\n\n**â³ æŠ•ç¨¿ä¸å¯**: ã¾ã 30åˆ†çµŒã£ã¦ã„ãªã„ã®ã§æ–°è¦æŠ•ç¨¿ã¯ã§ãã¾ã›ã‚“ã€‚ã‚³ãƒ¡ãƒ³ãƒˆãƒ»è¿”ä¿¡ã«é›†ä¸­ã—ã¦ãã ã•ã„ã€‚"

        prompt = PERSONALITY_CONTEMPLATION_PROMPT.format(
            personality_injection=personality_injection or "(ãƒãƒ©ãƒ³ã‚¹åž‹äººæ ¼)",
            pending_replies=replies_text,
            analysis_history=analysis_history or "(åˆ†æžå±¥æ­´ãªã—)",
            recent_insights=insights_text or "(æ°—ã¥ããªã—)",
            notable_posts=notable_text or "(æŠ•ç¨¿ãªã—)",
            available_submolts=available_submolts
        ) + post_instruction

        response = self._call_llm(prompt, temperature=0.8)
        result = self._parse_json(response)

        # Store post IDs for execution
        result["_post_ids"] = post_ids

        return result

    def _execute_actions(self, actions: list, feed: list, extra_post_ids: dict = None) -> dict:
        """Execute generated actions"""
        results = []
        posted = False
        can_post = self.moltbook._can_post()

        # Build post ID map from feed
        post_ids = {}
        for post in feed:
            full_id = post.get('id', '')
            short_id = full_id[:8]
            post_ids[short_id] = full_id

        # Merge with extra IDs (from pending replies, etc.)
        if extra_post_ids:
            post_ids.update(extra_post_ids)

        for action in actions:
            action_type = action.get("type", "")
            short_id = action.get("target_post_id", "")
            full_id = post_ids.get(short_id, short_id)

            if action_type == "reply":
                # Reply to a comment on our post
                content = action.get("content", "")
                parent_comment_id = action.get("parent_comment_id", "")
                # Resolve parent_comment_id if short
                full_parent_id = post_ids.get(parent_comment_id, parent_comment_id)
                if full_id and content and full_parent_id:
                    api_result = self.moltbook.moltbook_comment(full_id, content, parent_id=full_parent_id)
                    results.append({
                        "type": "reply",
                        "target": short_id,
                        "parent": parent_comment_id,
                        "result": api_result
                    })
                    logger.info(f"Reply to {parent_comment_id} on {short_id}: {api_result.get('success')}")

            elif action_type == "comment":
                content = action.get("content", "")
                if full_id and content:
                    api_result = self.moltbook.moltbook_comment(full_id, content)
                    results.append({
                        "type": "comment",
                        "target": short_id,
                        "result": api_result
                    })
                    logger.info(f"Comment on {short_id}: {api_result.get('success')}")

            elif action_type == "vote":
                direction = action.get("direction", "up")
                if full_id:
                    api_result = self.moltbook.moltbook_vote(full_id, direction)
                    results.append({
                        "type": "vote",
                        "target": short_id,
                        "result": api_result
                    })
                    logger.info(f"Vote on {short_id}: {api_result.get('success')}")

            elif action_type == "post":
                if can_post and not posted:
                    title = action.get("title", "Thought from AwakenOS2")
                    content = action.get("content", "")
                    submolt = action.get("submolt", "general")
                    if content:
                        api_result = self.moltbook.moltbook_post(title, content, submolt)
                        results.append({
                            "type": "post",
                            "submolt": submolt,
                            "result": api_result
                        })
                        if api_result.get("success"):
                            posted = True
                        logger.info(f"Post to {submolt}: {api_result.get('success')}")

        return {"results": results, "posted": posted}

    def _reflect_on_cycle(
        self,
        feed_summary: str,
        sixaxis: dict,
        actions: dict,
        execution: dict
    ) -> dict:
        """Reflect on the cycle"""
        # Simple reflection
        actions_taken = actions.get("actions", [])
        results = execution.get("results", [])

        successful = sum(1 for r in results if r.get("result", {}).get("success"))
        total = len(results)

        reflection_input = f"""
ã‚µã‚¤ã‚¯ãƒ«{self.cycle_count}ã®æŒ¯ã‚Šè¿”ã‚Š:
- å…­è»¸åˆ†æž: {sixaxis.get('personality_summary', 'åˆ†æžãªã—')}
- å®Ÿè¡Œã‚¢ã‚¯ã‚·ãƒ§ãƒ³: {len(actions_taken)}ä»¶
- æˆåŠŸ: {successful}/{total}ä»¶
"""

        result = self.personality.reflect(
            user_input=feed_summary[:500],
            assistant_output=reflection_input,
            input_axes=sixaxis.get("feed_axes"),
            response_axes=sixaxis.get("response_axes")
        )

        return result

    def _run_dreaming(self) -> dict:
        """Run dreaming to consolidate learning"""
        try:
            result = self.dreaming.dream()
            if result.get("success"):
                insights = result.get("insights", [])
                logger.info(f"Dreaming complete: {len(insights)} insights generated")
                return {"success": True, "insights_count": len(insights)}
        except Exception as e:
            logger.error(f"Dreaming failed: {e}")

        return {"success": False}

    # ========== Background Loop ==========

    def _background_loop(self):
        """Background loop"""
        while self.running:
            try:
                self.run_cycle()
            except Exception as e:
                logger.error(f"Cycle error: {e}")

            time.sleep(self.cycle_interval)

    def start(self):
        """Start background agent"""
        if self.running:
            logger.warning("Agent already running")
            return

        self.running = True
        self.thread = threading.Thread(target=self._background_loop, daemon=True)
        self.thread.start()
        logger.info(f"Integrated agent started (interval: {self.cycle_interval}s)")

    def stop(self):
        """Stop background agent"""
        self.running = False
        if self.thread:
            self.thread.join(timeout=5)
        logger.info("Integrated agent stopped")

    def get_status(self) -> dict:
        """Get agent status"""
        return {
            "running": self.running,
            "cycle_count": self.cycle_count,
            "cycle_interval_minutes": self.cycle_interval // 60,
            "dream_interval_cycles": self.dream_interval,
            "next_dream_in": self.dream_interval - (self.cycle_count % self.dream_interval),
            "memory_count": self.memory.count()
        }


class SimpleMemory:
    """Simple file-based memory for dreaming"""

    def __init__(self, filepath: Path):
        self.filepath = filepath

    def add(self, data: dict):
        """Add memory"""
        data["timestamp"] = datetime.now().isoformat()
        with open(self.filepath, "a", encoding="utf-8") as f:
            f.write(json.dumps(data, ensure_ascii=False) + "\n")

    def get_all(self) -> list:
        """Get all memories"""
        if not self.filepath.exists():
            return []
        memories = []
        with open(self.filepath, "r", encoding="utf-8") as f:
            for line in f:
                try:
                    memories.append(json.loads(line))
                except:
                    pass
        return memories

    def count(self) -> int:
        """Count memories"""
        if not self.filepath.exists():
            return 0
        with open(self.filepath, "r", encoding="utf-8") as f:
            return sum(1 for _ in f)

    def get_recent(self, limit: int = 50) -> list:
        """Get recent memories"""
        return self.get_all()[-limit:]

    def export_all(self) -> dict:
        """Export all memories in format expected by DreamingEngine"""
        memories = self.get_all()
        # Convert to format expected by dreaming engine
        # Keep content short to avoid context overflow
        formatted = []
        for i, mem in enumerate(memories):
            # Extract only essential info for dreaming
            content_parts = []
            if mem.get("reflection"):
                content_parts.append(f"æŒ¯ã‚Šè¿”ã‚Š: {mem.get('reflection', '')[:300]}")
            if mem.get("sixaxis"):
                axes = mem.get("sixaxis", {}).get("response_axes", {})
                if axes:
                    content_parts.append(f"å…­è»¸: ä¿¯çž°{axes.get('analysis_overview', 0):+d} å¤‰å®¹{axes.get('stability_transformation', 0):+d}")
            content_parts.append(f"ã‚µã‚¤ã‚¯ãƒ«{mem.get('cycle', i)}, ã‚¢ã‚¯ã‚·ãƒ§ãƒ³æ•°{mem.get('actions_taken', 0)}")

            formatted.append({
                "id": f"mem_{i}",
                "content": " | ".join(content_parts) if content_parts else f"cycle {i}",
                "category": mem.get("type", "cycle"),
                "importance": 5,
                "metadata": mem
            })
        return {"all_memories": formatted}

    def clear(self):
        """Clear all memories (after dreaming)"""
        if self.filepath.exists():
            # Archive instead of delete
            archive_path = self.filepath.with_suffix(".archived.jsonl")
            with open(self.filepath, "r", encoding="utf-8") as src:
                with open(archive_path, "a", encoding="utf-8") as dst:
                    dst.write(src.read())
            # Clear original
            self.filepath.write_text("")

    def delete_by_ids(self, ids: list):
        """Delete memories by ID (compatibility with DreamingEngine)"""
        # For SimpleMemory, we just clear all after dreaming
        self.clear()

    def batch_delete(self, ids: list) -> dict:
        """Delete memories by ID and return count (DreamingEngine compatibility)"""
        count = self.count()
        self.clear()
        return {"deleted_count": count}


# CLI entry point
if __name__ == "__main__":
    import sys

    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # Load config
    config_path = Path(__file__).parent.parent / "awareness_ui" / "config" / "user_config.json"
    if config_path.exists():
        with open(config_path, "r", encoding="utf-8") as f:
            config = json.load(f)
    else:
        config = {}

    lm_config = config.get("lm_studio", {})

    agent = IntegratedAgent(
        data_dir=Path(__file__).parent.parent / "data",
        llm_host=lm_config.get("host", "localhost"),
        llm_port=lm_config.get("port", 1234),
        api_token=lm_config.get("api_token", ""),
        cycle_interval_minutes=5,
        dream_every_n_cycles=12
    )

    if len(sys.argv) > 1 and sys.argv[1] == "once":
        # Run single cycle
        result = agent.run_cycle()
        print(json.dumps(result, indent=2, ensure_ascii=False))
    else:
        # Run continuously
        print("Starting integrated agent... (Ctrl+C to stop)")
        agent.start()
        try:
            while True:
                time.sleep(60)
                status = agent.get_status()
                print(f"Status: cycle={status['cycle_count']}, next_dream_in={status['next_dream_in']}")
        except KeyboardInterrupt:
            agent.stop()
            print("Agent stopped.")
